# Fun√ß√£o Zeta de Riemann

## Universidade Presbiteriana Mackenzie  
**Faculdade de Computa√ß√£o e Inform√°tica**

## üìò Introdu√ß√£o

Este projeto tem como objetivo aplicar t√©cnicas de computa√ß√£o paralela na busca por zeros da fun√ß√£o Zeta de Riemann no eixo cr√≠tico. Foram desenvolvidas duas vers√µes do algoritmo: uma **sequencial** e outra **paralela**, com o intuito de comparar desempenho e escalabilidade.

---

## Como usar o c√≥digo

### üîß Requisitos
Antes de compilar e executar o c√≥digo, verifique se voc√™ tem os seguintes requisitos instalados:

- [GCC](https://gcc.gnu.org/) com suporte a OpenMP
- Sistema Linux, WSL ou terminal com compilador compat√≠vel
- Make (opcional, se usar um Makefile)

### üß™ Compilando o c√≥digo

Primeiramente, v√° at√© a pasta dos c√≥digos baixados.
```bash
cd [nome_da_pasta]
```

Para compilar a vers√£o **sequencial**:

```bash
gcc -fopenmp -o serial serial.c -lm
```

Para compilar a vers√£o **paralela**:
```bash
gcc -fopenmp -o paralela paralela.c -lm
```

Para mudar a quantidade de Threads na vers√£o **paralela**:
v√° at√© a fun√ß√£o int main() e altere:
```bash
omp_set_num_threads(1); //altere a quantidade de threads
```
---

## ‚öôÔ∏è Descri√ß√£o

O programa realiza uma modelagem computacional da fun√ß√£o Zeta de Riemann, calculando os valores da fun√ß√£o Z(t) em um intervalo cont√≠nuo. A partir da an√°lise da mudan√ßa de sinais, √© poss√≠vel localizar os zeros da fun√ß√£o. 

A solu√ß√£o foi implementada em duas vers√µes:

### üîπ Solu√ß√£o Serial

Na vers√£o sequencial, todos os c√°lculos s√£o feitos em uma √∫nica thread. O algoritmo percorre o intervalo de forma cont√≠nua, verificando altera√ß√µes de sinal na fun√ß√£o Z(t) para contar os zeros. Essa abordagem √© simples e garante resultados consistentes.

### üî∏ Solu√ß√£o Paralela

A vers√£o paralela utiliza OpenMP para dividir o trabalho entre m√∫ltiplas threads. O c√°lculo de Z(t) √© feito de forma independente por cada thread, utilizando `#pragma omp parallel for schedule(static)`. Como os valores s√£o independentes, a paraleliza√ß√£o melhora significativamente o desempenho. A contagem dos zeros, no entanto, √© realizada de forma sequencial ap√≥s o c√°lculo paralelo.

---

## üìä Tabela de Testes

| Teste              | Threads | Serial (s) | Paralelo (s) | SpeedUp | Efici√™ncia |
|--------------------|---------|------------|---------------|---------|------------|
| 100 300 4000       | 1       | 8.898      | 5.321         | 1.67    | 1.67       |
|                    | 2       | 8.898      | 4.724         | 1.88    | 0.94       |
|                    | 3       | 8.898      | 1.922         | 4.63    | 1.54       |
|                    | 4       | 8.898      | 2.556         | 3.48    | 0.87       |
| 200 400 8000       | 1       | 13.950     | 10.486        | 1.33    | 1.33       |
|                    | 2       | 13.950     | 6.822         | 2.04    | 1.02       |
|                    | 3       | 13.950     | 5.444         | 2.56    | 0.85       |
|                    | 4       | 13.950     | 4.642         | 3.00    | 0.75       |
| 10 400 3000        | 1       | 8.351      | 6.312         | 1.32    | 1.32       |
|                    | 2       | 8.351      | 4.099         | 2.04    | 1.02       |
|                    | 3       | 8.351      | 2.775         | 3.01    | 1.00       |
|                    | 4       | 8.351      | 3.262         | 2.56    | 0.64       |
| 100 1004 10000     | 1       | 56.345     | 52.694        | 1.07    | 1.07       |
|                    | 2       | 56.345     | 33.269        | 1.69    | 0.85       |
|                    | 3       | 56.345     | 27.169        | 2.07    | 0.69       |
|                    | 4       | 56.345     | 23.577        | 2.39    | 0.60       |
| 200 2054 9878      | 1       | 116.531    | 122.008       | 0.96    | 0.96       |
|                    | 2       | 116.531    | 71.709        | 1.63    | 0.81       |
|                    | 3       | 116.531    | 69.055        | 1.69    | 0.56       |
|                    | 4       | 116.531    | 76.525        | 1.52    | 0.38       |

---

## üìà Gr√°ficos

Gr√°ficos de **SpeedUp** e **Efici√™ncia** foram gerados com base nos testes acima. Eles evidenciam o comportamento da paraleliza√ß√£o com o aumento do n√∫mero de threads.

### SpeedUp por n√∫mero de threads

![Gr√°fico de SpeedUp](./gr√°ficos/SpeedUp.PNG)


### Efici√™ncia por n√∫mero de threads

![Gr√°fico de SpeedUp](./gr√°ficos/Eficiencia.PNG)
---

## üß† Conclus√£o

De maneira geral, observa-se que o uso de m√∫ltiplas threads proporciona ganhos de desempenho significativos, especialmente nos testes com menor carga computacional, como o caso `100 300 4000`, que apresentou um *speedup* de at√© 3,48 ao utilizar 4 threads. No entanto, o ganho de desempenho n√£o cresce de forma linear com o n√∫mero de threads ‚Äî o que seria o cen√°rio ideal ‚Äî, evidenciando a presen√ßa de sobrecarga associada √† cria√ß√£o, sincroniza√ß√£o e gerenciamento de threads.

√Ä medida que o n√∫mero de threads aumenta, a efici√™ncia tende a diminuir, pois parte do tempo de execu√ß√£o √© consumida em tarefas de coordena√ß√£o entre as threads em vez de processamento √∫til. Isso fica evidente nos testes de maior porte, como `200 2054 9878`, em que a efici√™ncia com 4 threads caiu para apenas 0,38, demonstrando que o custo da paraleliza√ß√£o pode superar seus benef√≠cios dependendo do tamanho e da natureza da tarefa.

Outro ponto importante √© que diferentes testes reagem de forma distinta √† paraleliza√ß√£o. Enquanto alguns escalonam bem com o aumento de threads, outros apresentam ganhos mais limitados. Isso indica que o desempenho paralelo est√° fortemente ligado √†s caracter√≠sticas do problema, como a divis√£o equilibrada de tarefas e a quantidade de c√°lculos independentes que podem ser realizados simultaneamente.

Em s√≠ntese, a paraleliza√ß√£o da fun√ß√£o Zeta de Riemann pode trazer vantagens claras, mas seu benef√≠cio depende do equil√≠brio entre o custo de paraleliza√ß√£o e o ganho de desempenho. O n√∫mero ideal de threads varia conforme o tamanho do problema, sendo que, para muitos casos, o uso de 3 threads oferece um bom compromisso entre desempenho e efici√™ncia, enquanto o uso excessivo de threads pode gerar perda de desempenho devido ao overhead.

---

## üîó Refer√™ncias

- [OpenMP Specifications](https://www.openmp.org/specifications/)
- [arXiv: Zeta Function and Computation](https://arxiv.org/abs/2003.11069)
